{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Dataset --KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1=pd.read_csv('KNN_impute.csv')\n",
    "df1_vali=pd.read_csv('KNN_impute_validation.csv')\n",
    "df1_test=pd.read_csv('KNN_impute_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP-- upsampling KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def upsample(data):\n",
    "    from sklearn.utils import resample\n",
    "    \n",
    "    df_majority=data[data.Default_ind==0]\n",
    "    df_minority=data[data.Default_ind==1]\n",
    "    largenumber=len(df_majority)\n",
    "    df_minority_upsampled=resample(df_minority,replace=True,n_samples=int(1.2*largenumber),random_state=123)\n",
    "    df_upsampled=pd.concat([pd.DataFrame(df_majority),pd.DataFrame(df_minority_upsampled)])\n",
    "    return df_upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_up= upsample(df1)\n",
    "df1_vali_up=upsample(df1_vali)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cate_to_object_excp_inq(dataset):\n",
    "    return(dataset.astype({'non_mtg_acc_past_due_12_months_num': 'object','non_mtg_acc_past_due_6_months_num': 'object','mortgages_past_due_6_months_num': 'object','card_inq_24_month_num': 'float64','inq_12_month_num': 'float64','card_open_36_month_num': 'object','auto_open_36_month_num': 'object','ind_acc_XYZ': 'object'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_up=Cate_to_object_excp_inq(df1_up)\n",
    "df1_vali=Cate_to_object_excp_inq(df1_vali)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def para_tune(datatrain, datavali, criteria='accuracy', randomstate=0):\n",
    "    ## X is the validation set variables\n",
    "    ## Y is the validation set response\n",
    "    from sklearn.model_selection import PredefinedSplit\n",
    "    import numpy as np\n",
    "    frames=pd.concat([datatrain, datavali])\n",
    "    frames_reind=frames.set_index([pd.Index(range(len(frames)))])\n",
    "    split_index=[-1]*len(datatrain)+[0]*len(datavali)\n",
    "    pds = PredefinedSplit(test_fold = split_index)\n",
    "    datadummy=pd.get_dummies(frames_reind)\n",
    "    datatrainX=np.array(datadummy.drop('Default_ind', axis=1))\n",
    "    datatrainy=datadummy['Default_ind']\n",
    "    parameter_space = {\n",
    "        'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
    "        'activation': ['tanh', 'relu'],\n",
    "        'solver': ['lbfgs', 'adam'],\n",
    "        'alpha': [0.0001, 0.05],\n",
    "        'learning_rate': ['constant','adaptive'],\n",
    "    }\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    mlp = MLPClassifier(max_iter=1000)\n",
    "    clf = GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=pds,scoring=criteria)\n",
    "    clf.fit(datatrainX, datatrainy)\n",
    "    return clf,datatrainX,datatrainy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1,x1,y1=para_tune(df1_up,df1_vali_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tot_credit_debt</th>\n",
       "      <th>avg_card_debt</th>\n",
       "      <th>credit_age</th>\n",
       "      <th>credit_good_age</th>\n",
       "      <th>card_age</th>\n",
       "      <th>non_mtg_acc_past_due_12_months_num</th>\n",
       "      <th>non_mtg_acc_past_due_6_months_num</th>\n",
       "      <th>mortgages_past_due_6_months_num</th>\n",
       "      <th>credit_past_due_amount</th>\n",
       "      <th>inq_12_month_num</th>\n",
       "      <th>...</th>\n",
       "      <th>card_open_36_month_num</th>\n",
       "      <th>auto_open_36_month_num</th>\n",
       "      <th>uti_card</th>\n",
       "      <th>uti_50plus_pct</th>\n",
       "      <th>uti_max_credit_line</th>\n",
       "      <th>uti_card_50plus_pct</th>\n",
       "      <th>ind_acc_XYZ</th>\n",
       "      <th>rep_income</th>\n",
       "      <th>States</th>\n",
       "      <th>Default_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80826.71</td>\n",
       "      <td>15872.99</td>\n",
       "      <td>300</td>\n",
       "      <td>114</td>\n",
       "      <td>292</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.365902</td>\n",
       "      <td>0.475594</td>\n",
       "      <td>0.410504</td>\n",
       "      <td>0.387894</td>\n",
       "      <td>0</td>\n",
       "      <td>69000</td>\n",
       "      <td>AL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96052.60</td>\n",
       "      <td>12178.02</td>\n",
       "      <td>281</td>\n",
       "      <td>102</td>\n",
       "      <td>232</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.542786</td>\n",
       "      <td>0.543158</td>\n",
       "      <td>0.535147</td>\n",
       "      <td>0.587351</td>\n",
       "      <td>0</td>\n",
       "      <td>61000</td>\n",
       "      <td>FL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75212.76</td>\n",
       "      <td>12052.24</td>\n",
       "      <td>261</td>\n",
       "      <td>149</td>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.323678</td>\n",
       "      <td>0.321776</td>\n",
       "      <td>0.348713</td>\n",
       "      <td>0.413293</td>\n",
       "      <td>0</td>\n",
       "      <td>86500</td>\n",
       "      <td>AL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41604.47</td>\n",
       "      <td>10611.97</td>\n",
       "      <td>249</td>\n",
       "      <td>136</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.644030</td>\n",
       "      <td>0.619987</td>\n",
       "      <td>0.546655</td>\n",
       "      <td>0.588442</td>\n",
       "      <td>1</td>\n",
       "      <td>79500</td>\n",
       "      <td>LA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>89198.22</td>\n",
       "      <td>15193.09</td>\n",
       "      <td>319</td>\n",
       "      <td>147</td>\n",
       "      <td>279</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.183918</td>\n",
       "      <td>0.309341</td>\n",
       "      <td>0.254744</td>\n",
       "      <td>0.193060</td>\n",
       "      <td>0</td>\n",
       "      <td>76000</td>\n",
       "      <td>LA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tot_credit_debt  avg_card_debt  credit_age  credit_good_age  card_age  \\\n",
       "0         80826.71       15872.99         300              114       292   \n",
       "1         96052.60       12178.02         281              102       232   \n",
       "2         75212.76       12052.24         261              149       260   \n",
       "4         41604.47       10611.97         249              136       241   \n",
       "5         89198.22       15193.09         319              147       279   \n",
       "\n",
       "  non_mtg_acc_past_due_12_months_num non_mtg_acc_past_due_6_months_num  \\\n",
       "0                                  0                                 0   \n",
       "1                                  0                                 0   \n",
       "2                                  0                                 0   \n",
       "4                                  0                                 0   \n",
       "5                                  0                                 0   \n",
       "\n",
       "  mortgages_past_due_6_months_num  credit_past_due_amount  inq_12_month_num  \\\n",
       "0                               0                     0.0               3.0   \n",
       "1                               0                     0.0               2.0   \n",
       "2                               0                     0.0               1.0   \n",
       "4                               0                     0.0               0.0   \n",
       "5                               0                     0.0               2.0   \n",
       "\n",
       "   ...  card_open_36_month_num auto_open_36_month_num  uti_card  \\\n",
       "0  ...                       0                      0  0.365902   \n",
       "1  ...                       1                      0  0.542786   \n",
       "2  ...                       0                      1  0.323678   \n",
       "4  ...                       0                      0  0.644030   \n",
       "5  ...                       1                      0  0.183918   \n",
       "\n",
       "   uti_50plus_pct  uti_max_credit_line  uti_card_50plus_pct  ind_acc_XYZ  \\\n",
       "0        0.475594             0.410504             0.387894            0   \n",
       "1        0.543158             0.535147             0.587351            0   \n",
       "2        0.321776             0.348713             0.413293            0   \n",
       "4        0.619987             0.546655             0.588442            1   \n",
       "5        0.309341             0.254744             0.193060            0   \n",
       "\n",
       "  rep_income  States Default_ind  \n",
       "0      69000      AL           0  \n",
       "1      61000      FL           0  \n",
       "2      86500      AL           0  \n",
       "4      79500      LA           0  \n",
       "5      76000      LA           0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_up.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6661161279251839"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.score(x1,y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9092"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_test1=Cate_to_object_excp_inq(df1_test1)\n",
    "df1_test1=pd.get_dummies(df1_test1)\n",
    "clf1.score(df1_test1.drop('Default_ind',axis=1),df1_test1['Default_ind'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4360,  239],\n",
       "       [ 215,  186]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred1=clf1.predict(df1_test1.drop('Default_ind',axis=1))\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix( df1_test1['Default_ind'],y_pred1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Dataset --Unconditional median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df2=pd.read_csv('Unconditional_median_impute.csv')\n",
    "df2_vali=pd.read_csv('Unconditional_median_impute_validation.csv')\n",
    "df2_test=pd.read_csv('Unconditional_median_impute_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP-- Unconditional median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_up= upsample(df2)\n",
    "df2_vali_up=upsample(df2_vali)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_up=Cate_to_object_excp_inq(df2_up)\n",
    "df2_vali=Cate_to_object_excp_inq(df2_vali_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2,x2,y2=para_tune(df2_up,df2_vali_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5454408957336823"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.score(x2,y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0802"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_test1=Cate_to_object_excp_inq(df2_test)\n",
    "df2_test1=pd.get_dummies(df2_test1)\n",
    "clf2.score(df2_test1.drop('Default_ind',axis=1),df2_test1['Default_ind'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0, 4599],\n",
       "       [   0,  401]])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred2=clf2.predict(df2_test1.drop('Default_ind',axis=1))\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix( df2_test1['Default_ind'],y_pred2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Dataset -- drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df3=pd.read_csv('Listwise_deletion.csv')\n",
    "df3_vali=pd.read_csv('Listwise_deletion_validation.csv')\n",
    "df3_test=pd.read_csv('Listwise_deletion_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP -- drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_up= upsample(df3)\n",
    "df3_vali_up=upsample(df3_vali)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_up=Cate_to_object_excp_inq(df3_up)\n",
    "df3_vali=Cate_to_object_excp_inq(df3_vali)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf3,x3,y3=para_tune(df3_up,df3_vali_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6432508118092174"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3.score(x3,y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9337509033967719"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_test1=Cate_to_object_excp_inq(df3_test)\n",
    "df3_test1=pd.get_dummies(df3_test1)\n",
    "clf3.score(df3_test1.drop('Default_ind',axis=1),df3_test1['Default_ind'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3736,   74],\n",
       "       [ 201,  140]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred3=clf3.predict(df3_test1.drop('Default_ind',axis=1))\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(df3_test1['Default_ind'],y_pred3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Dataset -- EM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df4=pd.read_csv('Simulated_Data_Train_em.csv')\n",
    "df4_vali=pd.read_csv('Simulated_Data_validatiion_em.csv')\n",
    "df4_test=pd.read_csv('Simulated_Data_test_em.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP -- EM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_up= upsample(df4)\n",
    "df4_vali_up=upsample(df4_vali)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_up=Cate_to_object_excp_inq(df4_up)\n",
    "df4_vali_up=Cate_to_object_excp_inq(df4_vali_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf4,x4,y4=para_tune(df4_up,df4_vali_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5454446009325475"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf4.score(x4,y4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 526 features, but MLPClassifier is expecting 1716 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-229-4dc32b171f55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf4_test1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCate_to_object_excp_inq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf4_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf4_test1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf4_test1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclf4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf4_test1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Default_ind'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf4_test1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Default_ind'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;31m# callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscorer_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultimetric_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefit\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0mScore\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mapplied\u001b[0m \u001b[0mto\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0mof\u001b[0m \u001b[0mestimator\u001b[0m \u001b[0mon\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \"\"\"\n\u001b[0;32m--> 199\u001b[0;31m         return self._score(partial(_cached_call, None), estimator, X, y_true,\n\u001b[0m\u001b[1;32m    200\u001b[0m                            sample_weight=sample_weight)\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(self, method_caller, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \"\"\"\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod_caller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"predict\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m             return self._sign * self._score_func(y_true, y_pred,\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m_cached_call\u001b[0;34m(cache, estimator, method, *args, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;34m\"\"\"Call estimator with method and args and kwargs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \"\"\"\n\u001b[1;32m   1033\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pass_fast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_forward_pass_fast\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mdecision\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \"\"\"\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;31m# Initialize first layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ensure_2d'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    366\u001b[0m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m                 f\"is expecting {self.n_features_in_} features as input.\")\n",
      "\u001b[0;31mValueError\u001b[0m: X has 526 features, but MLPClassifier is expecting 1716 features as input."
     ]
    }
   ],
   "source": [
    "df4_test1=Cate_to_object_excp_inq(df4_test)\n",
    "df4_test1=pd.get_dummies(df4_test1)\n",
    "clf4.score(df4_test1.drop('Default_ind',axis=1),df4_test1['Default_ind'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred4=clf4.predict(df4_test1.drop('Default_ind',axis=1))\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(df4_test1['Default_ind'],y_pred4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Dataset -- CART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df5=pd.read_csv('cart_impute.csv')\n",
    "df5_vali=pd.read_csv('cart_impute_vali.csv')\n",
    "df5_test=pd.read_csv('cart_impute_Test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP--cart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5_up= upsample(df5)\n",
    "df5_vali_up=upsample(df5_vali)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5_up=Cate_to_object_excp_inq(df5_up)\n",
    "df5_vali=Cate_to_object_excp_inq(df5_vali)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf5,x5,y5=para_tune(df5_up,df5_vali_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6527745007614594"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf5.score(x5,y5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9156"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5_test1=Cate_to_object_excp_inq(df5_test)\n",
    "df5_test1=pd.get_dummies(df5_test1)\n",
    "clf5.score(df5_test1.drop('Default_ind',axis=1),df5_test1['Default_ind'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4420,  179],\n",
       "       [ 243,  158]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred5=clf5.predict(df5_test1.drop('Default_ind',axis=1))\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(df5_test1['Default_ind'],y_pred5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data --RF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df6=pd.read_csv('rf.csv')\n",
    "df6_vali=pd.read_csv('rf_Vali.csv')\n",
    "df6_test=pd.read_csv('rf_Test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP--RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6_up= upsample(df6)\n",
    "df6_vali_up=upsample(df6_vali)\n",
    "df6_up=Cate_to_object_excp_inq(df6_up)\n",
    "df6_vali=Cate_to_object_excp_inq(df6_vali)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf6,x6,y6=para_tune(df6_up,df6_vali_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6643143647712404"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf6.score(x6,y6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8786"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6_test1=Cate_to_object_excp_inq(df6_test)\n",
    "df6_test1=pd.get_dummies(df6_test1)\n",
    "clf6.score(df6_test1.drop('Default_ind',axis=1),df6_test1['Default_ind'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4186,  413],\n",
       "       [ 194,  207]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred6=clf6.predict(df6_test1.drop('Default_ind',axis=1))\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(df6_test1['Default_ind'],y_pred6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data --EMB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df7=pd.read_csv('EMB_impute.csv')\n",
    "df7_vali=pd.read_csv('EMB_impute_Vali.csv')\n",
    "df7_test=pd.read_csv('EMB_impute_Test.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP--EMB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7_up= upsample(df7)\n",
    "df7_vali_up=upsample(df7_vali)\n",
    "df7_up=Cate_to_object_excp_inq(df7_up)\n",
    "df7_vali=Cate_to_object_excp_inq(df7_vali)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf7,x7,y7=para_tune(df7_up,df7_vali_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6298663692327492"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf7.score(x7,y7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9336"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df7_test1=Cate_to_object_excp_inq(df7_test)\n",
    "df7_test1=pd.get_dummies(df7_test1)\n",
    "clf7.score(df7_test1.drop('Default_ind',axis=1),df7_test1['Default_ind'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4530,   69],\n",
       "       [ 263,  138]])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred7=clf7.predict(df7_test1.drop('Default_ind',axis=1))\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(df7_test1['Default_ind'],y_pred7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data-- unconditional mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dfn=pd.read_csv('Unconditional_mean_impute_Test.csv')\n",
    "dfn_vali=pd.read_csv('Unconditional_mean_impute_Validation.csv')\n",
    "dfn_test=pd.read_csv('Unconditional_mean_impute_Test.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn_up= upsample(dfn)\n",
    "dfn_vali_up=upsample(dfn_vali)\n",
    "dfn_up=Cate_to_object_excp_inq(dfn_up)\n",
    "dfn_vali=Cate_to_object_excp_inq(dfn_vali)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfn,xn,yn=para_tune(dfn_up,dfn_vali_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6411141237367513"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfn.score(xn,yn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.931"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfn_test1=Cate_to_object_excp_inq(dfn_test)\n",
    "dfn_test1=pd.get_dummies(dfn_test1)\n",
    "clfn.score(dfn_test1.drop('Default_ind',axis=1),dfn_test1['Default_ind'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4511,   88],\n",
       "       [ 257,  144]])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predn=clfn.predict(dfn_test1.drop('Default_ind',axis=1))\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(dfn_test1['Default_ind'],y_predn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGboost --KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boost(datatrain,datavali, nestimator=100, learningrate=1.0, maxdepth=1, randomstate=0):\n",
    "    '''\n",
    "    if not specified, the parameters are nestimator=100, criterion=\"gini\", max_depth=8, min_samples_split=400, \n",
    "    min_samples_leaf=50, bootstrap=True, oob_score=False, warm_start=False, max_samples=3000, random_state=0\n",
    "    '''\n",
    "    import numpy as np\n",
    "    from xgboost.sklearn import XGBClassifier\n",
    "    datatraindummy=pd.get_dummies(datatrain)\n",
    "    datatrainX=np.array(datatraindummy.drop('Default_ind', axis=1))\n",
    "    datatrainy=datatraindummy['Default_ind']\n",
    "    \n",
    "    XGB=XGBClassifier(n_estimators=nestimator, learning_rate=learningrate, max_depth=maxdepth, random_state=randomstate)\n",
    "    \n",
    "    '''RFclass = RandomForestClassifier(n_estimators=nestimator, criterion=criter,\n",
    "                                     max_depth=mdepth, min_samples_split=misamples_split, \n",
    "                                     min_samples_leaf=misamples_leaf, bootstrap=bootstra,\n",
    "                                     oob_score=oobscore, warm_start=warmstart,\n",
    "                                     max_samples=maxsamples, random_state=randomstate)\n",
    "    ''' \n",
    "    modelRF=XGB.fit(datatrainX,datatrainy)\n",
    "    \n",
    "    return(modelRF,datatrainX,datatrainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf6,x6,y6=boost(df1_up,df1_vali_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])),\n",
       "             estimator=MLPClassifier(max_iter=1000), n_jobs=-1,\n",
       "             param_grid={'activation': ['tanh', 'relu'],\n",
       "                         'alpha': [0.0001, 0.05],\n",
       "                         'hidden_layer_sizes': [(50, 50, 50), (50, 100, 50),\n",
       "                                                (100,)],\n",
       "                         'learning_rate': ['constant', 'adaptive'],\n",
       "                         'solver': ['lbfgs', 'adam']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf6.fit(x6,y6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6856781278822848"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf6.score(x6,y6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7738"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6_test1=Cate_to_object_excp_inq(df1_test)\n",
    "df6_test1=pd.get_dummies(df6_test1)\n",
    "clf6.score(df6_test1.drop('Default_ind',axis=1),df6_test1['Default_ind'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3629,  970],\n",
       "       [ 161,  240]])"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred6=clf6.predict(df6_test1.drop('Default_ind',axis=1))\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(df6_test1['Default_ind'],y_pred6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_xgboost(datatrain, datavali, criteria='accuracy', randomstate=0):\n",
    "    '''\n",
    "    if not specified, the parameters are n_estimators=100, criterion=\"gini\", max_depth=8, min_samples_split=400, \n",
    "    min_samples_leaf=50, bootstrap=True, oob_score=False, warm_start=False, max_samples=3000, random_state=0\n",
    "    '''\n",
    "    from sklearn.model_selection import PredefinedSplit\n",
    "    import numpy as np\n",
    "    from xgboost.sklearn import XGBClassifier\n",
    "    frames=pd.concat([datatrain, datavali])\n",
    "    frames_reind=frames.set_index([pd.Index(range(len(frames)))])\n",
    "    split_index=[-1]*len(datatrain)+[0]*len(datavali)\n",
    "    pds = PredefinedSplit(test_fold = split_index)\n",
    "    datadummy=pd.get_dummies(frames_reind)\n",
    "    datatrainX=np.array(datadummy.drop('Default_ind', axis=1))\n",
    "    datatrainy=datadummy['Default_ind']\n",
    "    \n",
    "    XGB=XGBClassifier()\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    parameter_space = {\n",
    "        'loss':['deviance', 'exponential'],\n",
    "        'n_estimators': [100,300],\n",
    "        'subsample': [0.5, 1],\n",
    "        'criterion':['friedman_mse', 'mse'], \n",
    "        'max_depth':range(3,10,2),\n",
    "    }\n",
    "    modelGS=GridSearchCV(XGB, parameter_space,cv=pds,scoring=criteria)\n",
    "    modelGS.fit(datatrainX, datatrainy)\n",
    "    return modelGS,datatrainX,datatrainy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "XGBoost Library (libxgboost.dylib) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed (vcomp140.dll or libgomp-1.dll for Windows, libomp.dylib for Mac OSX, libgomp.so for Linux and other UNIX-like OSes). Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n  * You are running 32-bit Python on a 64-bit OS\nError message(s): ['dlopen(/opt/anaconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.dylib, 6): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\\n  Referenced from: /opt/anaconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: image not found']\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-2c4e80e97f30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m xgb1 = XGBClassifier(\n\u001b[1;32m      3\u001b[0m  \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m  \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m  \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/xgboost/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDeviceQuantileDMatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrabit\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;31m# load the XGBoost library globally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m \u001b[0m_LIB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_lib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_load_lib\u001b[0;34m()\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlib_success\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mlibname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         raise XGBoostError(\n\u001b[0m\u001b[1;32m    158\u001b[0m             \u001b[0;34m'XGBoost Library ({}) could not be loaded.\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0;34m'Likely causes:\\n'\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mXGBoostError\u001b[0m: XGBoost Library (libxgboost.dylib) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed (vcomp140.dll or libgomp-1.dll for Windows, libomp.dylib for Mac OSX, libgomp.so for Linux and other UNIX-like OSes). Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n  * You are running 32-bit Python on a 64-bit OS\nError message(s): ['dlopen(/opt/anaconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.dylib, 6): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\\n  Referenced from: /opt/anaconda3/lib/python3.8/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: image not found']\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb1 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb1, x6, y6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_xgboost(datatrain, datavali, criteria='accuracy', randomstate=0):\n",
    "    '''\n",
    "    if not specified, the parameters are n_estimators=100, criterion=\"gini\", max_depth=8, min_samples_split=400, \n",
    "    min_samples_leaf=50, bootstrap=True, oob_score=False, warm_start=False, max_samples=3000, random_state=0\n",
    "    '''\n",
    "    from sklearn.model_selection import PredefinedSplit\n",
    "    import numpy as np\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    frames=pd.concat([datatrain, datavali])\n",
    "    frames_reind=frames.set_index([pd.Index(range(len(frames)))])\n",
    "    split_index=[-1]*len(datatrain)+[0]*len(datavali)\n",
    "    pds = PredefinedSplit(test_fold = split_index)\n",
    "    datadummy=pd.get_dummies(frames_reind)\n",
    "    datatrainX=np.array(datadummy.drop('Default_ind', axis=1))\n",
    "    datatrainy=datadummy['Default_ind']\n",
    "    \n",
    "    XGB=GradientBoostingClassifier()\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    parameter_space = {\n",
    "        'loss':['deviance', 'exponential'],\n",
    "    }\n",
    "    modelGS=GridSearchCV(XGB, parameter_space,cv=pds,scoring=criteria)\n",
    "    modelGS.fit(datatrainX, datatrainy)\n",
    "    return modelGS,datatrainX,datatrainy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf7,x7,y7=best_xgboost(df1_up,df1_vali_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_xgboost(datatrain, datavali, criteria='accuracy', randomstate=0):\n",
    "    '''\n",
    "    if not specified, the parameters are n_estimators=100, criterion=\"gini\", max_depth=8, min_samples_split=400, \n",
    "    min_samples_leaf=50, bootstrap=True, oob_score=False, warm_start=False, max_samples=3000, random_state=0\n",
    "    '''\n",
    "    from sklearn.model_selection import PredefinedSplit\n",
    "    import numpy as np\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    frames=pd.concat([datatrain, datavali])\n",
    "    frames_reind=frames.set_index([pd.Index(range(len(frames)))])\n",
    "    split_index=[-1]*len(datatrain)+[0]*len(datavali)\n",
    "    pds = PredefinedSplit(test_fold = split_index)\n",
    "    datadummy=pd.get_dummies(frames_reind)\n",
    "    datatrainX=np.array(datadummy.drop('Default_ind', axis=1))\n",
    "    datatrainy=datadummy['Default_ind']\n",
    "    \n",
    "    XGB=GradientBoostingClassifier(loss='exponential')\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    parameter_space = {\n",
    "        'n_estimators': [100,300]\n",
    "        \n",
    "    }\n",
    "    modelGS=GridSearchCV(XGB,parameter_space,cv=pds,scoring=criteria)\n",
    "    modelGS.fit(datatrainX, datatrainy)\n",
    "    return modelGS,datatrainX,datatrainy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf7,x7,y7=best_xgboost(df1_up,df1_vali_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 100}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf7.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_xgboost(datatrain, datavali, criteria='accuracy', randomstate=0):\n",
    "    '''\n",
    "    if not specified, the parameters are n_estimators=100, criterion=\"gini\", max_depth=8, min_samples_split=400, \n",
    "    min_samples_leaf=50, bootstrap=True, oob_score=False, warm_start=False, max_samples=3000, random_state=0\n",
    "    '''\n",
    "    from sklearn.model_selection import PredefinedSplit\n",
    "    import numpy as np\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    frames=pd.concat([datatrain, datavali])\n",
    "    frames_reind=frames.set_index([pd.Index(range(len(frames)))])\n",
    "    split_index=[-1]*len(datatrain)+[0]*len(datavali)\n",
    "    pds = PredefinedSplit(test_fold = split_index)\n",
    "    datadummy=pd.get_dummies(frames_reind)\n",
    "    datatrainX=np.array(datadummy.drop('Default_ind', axis=1))\n",
    "    datatrainy=datadummy['Default_ind']\n",
    "    \n",
    "    XGB=GradientBoostingClassifier(loss='exponential')\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    parameter_space = {\n",
    "        'n_estimators': range(50,100,10),\n",
    "    }\n",
    "    modelGS=GridSearchCV(XGB, parameter_space,cv=pds,scoring=criteria)\n",
    "    modelGS.fit(datatrainX, datatrainy)\n",
    "    return modelGS,datatrainX,datatrainy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf7,x7,y7=best_xgboost(df1_up,df1_vali_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 90}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf7.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_xgboost(datatrain, datavali, criteria='accuracy', randomstate=0):\n",
    "    '''\n",
    "    if not specified, the parameters are n_estimators=100, criterion=\"gini\", max_depth=8, min_samples_split=400, \n",
    "    min_samples_leaf=50, bootstrap=True, oob_score=False, warm_start=False, max_samples=3000, random_state=0\n",
    "    '''\n",
    "    from sklearn.model_selection import PredefinedSplit\n",
    "    import numpy as np\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    frames=pd.concat([datatrain, datavali])\n",
    "    frames_reind=frames.set_index([pd.Index(range(len(frames)))])\n",
    "    split_index=[-1]*len(datatrain)+[0]*len(datavali)\n",
    "    pds = PredefinedSplit(test_fold = split_index)\n",
    "    datadummy=pd.get_dummies(frames_reind)\n",
    "    datatrainX=np.array(datadummy.drop('Default_ind', axis=1))\n",
    "    datatrainy=datadummy['Default_ind']\n",
    "    \n",
    "    XGB=GradientBoostingClassifier(loss='exponential',n_estimators=90)\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    parameter_space = {\n",
    "        'subsample':[0.5,1]\n",
    "    }\n",
    "    modelGS=GridSearchCV(XGB, parameter_space,cv=pds,scoring=criteria)\n",
    "    modelGS.fit(datatrainX, datatrainy)\n",
    "    return modelGS,datatrainX,datatrainy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf7,x7,y7=best_xgboost(df1_up,df1_vali_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subsample': 1}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf7.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_xgboost(datatrain, datavali, criteria='accuracy', randomstate=0):\n",
    "    '''\n",
    "    if not specified, the parameters are n_estimators=100, criterion=\"gini\", max_depth=8, min_samples_split=400, \n",
    "    min_samples_leaf=50, bootstrap=True, oob_score=False, warm_start=False, max_samples=3000, random_state=0\n",
    "    '''\n",
    "    from sklearn.model_selection import PredefinedSplit\n",
    "    import numpy as np\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    frames=pd.concat([datatrain, datavali])\n",
    "    frames_reind=frames.set_index([pd.Index(range(len(frames)))])\n",
    "    split_index=[-1]*len(datatrain)+[0]*len(datavali)\n",
    "    pds = PredefinedSplit(test_fold = split_index)\n",
    "    datadummy=pd.get_dummies(frames_reind)\n",
    "    datatrainX=np.array(datadummy.drop('Default_ind', axis=1))\n",
    "    datatrainy=datadummy['Default_ind']\n",
    "    \n",
    "    XGB=GradientBoostingClassifier(loss='exponential',n_estimators=90,subsample=1)\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    parameter_space = {\n",
    "        'criterion':['friedman_mse', 'mse']\n",
    "    }\n",
    "    modelGS=GridSearchCV(XGB, parameter_space,cv=pds,scoring=criteria)\n",
    "    modelGS.fit(datatrainX, datatrainy)\n",
    "    return modelGS,datatrainX,datatrainy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf7,x7,y7=best_xgboost(df1_up,df1_vali_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'friedman_mse'}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf7.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_xgboost(datatrain, datavali, criteria='accuracy', randomstate=0):\n",
    "    '''\n",
    "    if not specified, the parameters are n_estimators=100, criterion=\"gini\", max_depth=8, min_samples_split=400, \n",
    "    min_samples_leaf=50, bootstrap=True, oob_score=False, warm_start=False, max_samples=3000, random_state=0\n",
    "    '''\n",
    "    from sklearn.model_selection import PredefinedSplit\n",
    "    import numpy as np\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    frames=pd.concat([datatrain, datavali])\n",
    "    frames_reind=frames.set_index([pd.Index(range(len(frames)))])\n",
    "    split_index=[-1]*len(datatrain)+[0]*len(datavali)\n",
    "    pds = PredefinedSplit(test_fold = split_index)\n",
    "    datadummy=pd.get_dummies(frames_reind)\n",
    "    datatrainX=np.array(datadummy.drop('Default_ind', axis=1))\n",
    "    datatrainy=datadummy['Default_ind']\n",
    "    \n",
    "    XGB=GradientBoostingClassifier(loss='exponential',n_estimators=90,subsample=1,criterion='friedman_mse')\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    parameter_space = {'max_depth':range(1,7,2)\n",
    "        \n",
    "    }\n",
    "    modelGS=GridSearchCV(XGB, parameter_space,cv=pds,scoring=criteria)\n",
    "    modelGS.fit(datatrainX, datatrainy)\n",
    "    return modelGS,datatrainX,datatrainy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf7,x7,y7=best_xgboost(df1_up,df1_vali_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 3}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf7.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_xgboost(datatrain, datavali, criteria='accuracy', randomstate=0):\n",
    "    '''\n",
    "    if not specified, the parameters are n_estimators=100, criterion=\"gini\", max_depth=8, min_samples_split=400, \n",
    "    min_samples_leaf=50, bootstrap=True, oob_score=False, warm_start=False, max_samples=3000, random_state=0\n",
    "    '''\n",
    "    from sklearn.model_selection import PredefinedSplit\n",
    "    import numpy as np\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    frames=pd.concat([datatrain, datavali])\n",
    "    frames_reind=frames.set_index([pd.Index(range(len(frames)))])\n",
    "    split_index=[-1]*len(datatrain)+[0]*len(datavali)\n",
    "    pds = PredefinedSplit(test_fold = split_index)\n",
    "    datadummy=pd.get_dummies(frames_reind)\n",
    "    datatrainX=np.array(datadummy.drop('Default_ind', axis=1))\n",
    "    datatrainy=datadummy['Default_ind']\n",
    "    \n",
    "    XGB=GradientBoostingClassifier(loss='exponential',subsample=1,criterion='friedman_mse')\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    parameter_space = {'max_depth':range(1,7,2),\n",
    "                        'n_estimators':range(80,100,5)\n",
    "    }\n",
    "    modelGS=GridSearchCV(XGB, parameter_space,cv=pds,scoring=criteria)\n",
    "    modelGS.fit(datatrainX, datatrainy)\n",
    "    return modelGS,datatrainX,datatrainy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf7,x7,y7=best_xgboost(df1_up,df1_vali_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])),\n",
       "             estimator=MLPClassifier(max_iter=1000), n_jobs=-1,\n",
       "             param_grid={'activation': ['tanh', 'relu'],\n",
       "                         'alpha': [0.0001, 0.05],\n",
       "                         'hidden_layer_sizes': [(50, 50, 50), (50, 100, 50),\n",
       "                                                (100,)],\n",
       "                         'learning_rate': ['constant', 'adaptive'],\n",
       "                         'solver': ['lbfgs', 'adam']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf7.fit(x7,y7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 3, 'n_estimators': 90}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf7.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8978"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df7_test1=Cate_to_object_excp_inq(df1_test)\n",
    "df7_test1=pd.get_dummies(df7_test1)\n",
    "clf7.score(df7_test1.drop('Default_ind',axis=1),df7_test1['Default_ind'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4298,  301],\n",
       "       [ 210,  191]])"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred7=clf7.predict(df7_test1.drop('Default_ind',axis=1))\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(df7_test1['Default_ind'],y_pred7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGboost --drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_xgboost(datatrain, datavali, criteria='accuracy', randomstate=0):\n",
    "    '''\n",
    "    if not specified, the parameters are n_estimators=100, criterion=\"gini\", max_depth=8, min_samples_split=400, \n",
    "    min_samples_leaf=50, bootstrap=True, oob_score=False, warm_start=False, max_samples=3000, random_state=0\n",
    "    '''\n",
    "    from sklearn.model_selection import PredefinedSplit\n",
    "    import numpy as np\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    frames=pd.concat([datatrain, datavali])\n",
    "    frames_reind=frames.set_index([pd.Index(range(len(frames)))])\n",
    "    split_index=[-1]*len(datatrain)+[0]*len(datavali)\n",
    "    pds = PredefinedSplit(test_fold = split_index)\n",
    "    datadummy=pd.get_dummies(frames_reind)\n",
    "    datatrainX=np.array(datadummy.drop('Default_ind', axis=1))\n",
    "    datatrainy=datadummy['Default_ind']\n",
    "    \n",
    "    XGB=GradientBoostingClassifier(loss='exponential',subsample=1,criterion='friedman_mse')\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    parameter_space = {'max_depth':range(1,7,2),\n",
    "                        'n_estimators':range(80,100,5)\n",
    "    }\n",
    "    modelGS=GridSearchCV(XGB, parameter_space,cv=pds,scoring=criteria)\n",
    "    modelGS.fit(datatrainX, datatrainy)\n",
    "    return modelGS,datatrainX,datatrainy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf8,x8,y8=best_xgboost(df3_up,df3_vali_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8647779068728215"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf8.score(x3,y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8277523488316069"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf8.score(df3_test1.drop('Default_ind',axis=1),df3_test1['Default_ind'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3182,  628],\n",
       "       [  87,  254]])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred8=clf8.predict(df3_test1.drop('Default_ind',axis=1))\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(df3_test1['Default_ind'],y_pred8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost -CART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf9,x9,y9=best_xgboost(df5_up,df5_vali_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 3, 'n_estimators': 95}"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf9.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf9_up=GradientBoostingClassifier(max_depth=3,n_estimators=95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(n_estimators=95)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf9_up.fit(x9,y9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.797"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "clf9_up.score(df5_test1.drop('Default_ind',axis=1),df5_test1['Default_ind'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3668,  931],\n",
       "       [  84,  317]])"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred9=clf9_up.predict(df5_test1.drop('Default_ind',axis=1))\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(df5_test1['Default_ind'],y_pred9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-270-0ef75ddf666a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf9\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;31m# fit the boosting stages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m         n_stages = self._fit_stages(\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m             sample_weight_val, begin_at_stage, monitor)\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m             \u001b[0;31m# fit next stage of trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m             raw_predictions = self._fit_stage(\n\u001b[0m\u001b[1;32m    562\u001b[0m                 \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                 random_state, X_csc, X_csr)\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m             tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0m\u001b[1;32m    215\u001b[0m                      check_input=False)\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1245\u001b[0m         \"\"\"\n\u001b[1;32m   1246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1247\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m   1248\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    387\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clf9.fit(x9,y9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost -RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf10,x10,y10=best_xgboost(df6_up,df6_vali_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 3, 'n_estimators': 95}"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf10.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf10_up=GradientBoostingClassifier(max_depth=3,n_estimators=95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(n_estimators=95)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf10_up.fit(x10,y10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7976"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf10_up.score(df6_test1.drop('Default_ind',axis=1),df6_test1['Default_ind'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3666,  933],\n",
       "       [  79,  322]])"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred10=clf10_up.predict(df6_test1.drop('Default_ind',axis=1))\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(df6_test1['Default_ind'],y_pred10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost --EMB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf11,x11,y11=best_xgboost(df7_up,df7_vali_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17116,  4076],\n",
       "       [ 4638, 20791]])"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf11.fit(x11, y11)\n",
    "confusion_matrix(y11,clf11.predict(x11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8130885223397182"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf11.score(x11,y11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.799"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf11.score(df7_test1.drop('Default_ind',axis=1),df7_test1['Default_ind'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3673,  926],\n",
       "       [  79,  322]])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred11=clf11.predict(df7_test1.drop('Default_ind',axis=1))\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(df7_test1['Default_ind'],y_pred11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost -- Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf12,x12,y12=best_xgboost(df2_up,df2_vali_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17087,  4105],\n",
       "       [ 4654, 20775]])"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clf11.fit(x11, y11)\n",
    "confusion_matrix(y12,clf12.predict(x12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.812123292078677"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf12.score(x12,y12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8012"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf12.score(df2_test1.drop('Default_ind',axis=1),df2_test1['Default_ind'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3678,  921],\n",
       "       [  73,  328]])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred12=clf12.predict(df2_test1.drop('Default_ind',axis=1))\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(df2_test1['Default_ind'],y_pred12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost -- mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf13,x13,y13=best_xgboost(dfn_up,dfn_vali_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 1, 'n_estimators': 95}"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf13.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf13_up=GradientBoostingClassifier(max_depth=1,n_estimators=95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(max_depth=1, n_estimators=95)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf13_up.fit(x13,y13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8138"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf13_up.score(dfn_test1.drop('Default_ind',axis=1),dfn_test1['Default_ind'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3739,  860],\n",
       "       [  75,  326]])"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred13=clf13.predict(dfn_test1.drop('Default_ind',axis=1))\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(dfn_test1['Default_ind'],y_pred13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
